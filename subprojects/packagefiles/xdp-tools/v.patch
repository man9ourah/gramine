diff --git a/headers/xdp/xsk.h b/headers/xdp/xsk.h
index 50ed537..45120e8 100644
--- a/headers/xdp/xsk.h
+++ b/headers/xdp/xsk.h
@@ -12,10 +12,12 @@
 #ifndef __LIBBPF_XSK_H
 #define __LIBBPF_XSK_H
 
+#include <err.h>
 #include <stdio.h>
 #include <stdint.h>
 #include <bpf/libbpf.h>
 #include <linux/if_xdp.h>
+#include <stdlib.h>
 
 #ifdef __cplusplus
 extern "C" {
@@ -46,40 +48,67 @@ DEFINE_XSK_RING(xsk_ring_cons);
 struct xsk_umem;
 struct xsk_socket;
 
+// HACK: This is very very wrong,, this is why it is called PoC ;(...
+struct xdp_umem_reg umem_config_validation;
+
 XDP_ALWAYS_INLINE __u64 *xsk_ring_prod__fill_addr(struct xsk_ring_prod *fill,
 					      __u32 idx)
 {
+    // fill->ring is saved in trusted memory during init
+    // it is a pointer to untrusted memory
 	__u64 *addrs = (__u64 *)fill->ring;
 
+    // fill->mask is also in trusted memory,
+    // ensuring that addrs[idx & fill->mask] is within ring mapped area
 	return &addrs[idx & fill->mask];
 }
 
 XDP_ALWAYS_INLINE const __u64 *
 xsk_ring_cons__comp_addr(const struct xsk_ring_cons *comp, __u32 idx)
 {
+    // comp->ring is saved in trusted memory during init
+    // it is a pointer to untrusted memory
 	const __u64 *addrs = (const __u64 *)comp->ring;
 
+    // comp->mask is also in trusted memory,
+    // ensuring that addrs[idx & comp->mask] is within ring mapped area
 	return &addrs[idx & comp->mask];
 }
 
 XDP_ALWAYS_INLINE struct xdp_desc *xsk_ring_prod__tx_desc(struct xsk_ring_prod *tx,
 						      __u32 idx)
 {
+    // tx->ring is saved in trusted memory during init
+    // it is a pointer to untrusted memory
 	struct xdp_desc *descs = (struct xdp_desc *)tx->ring;
 
+    // tx->mask is also in trusted memory,
+    // ensuring that descs[idx & tx->mask] is within ring mapped area
+    // since we are producers here, we can ignore whatever within the returned descs
 	return &descs[idx & tx->mask];
 }
 
 XDP_ALWAYS_INLINE const struct xdp_desc *
 xsk_ring_cons__rx_desc(const struct xsk_ring_cons *rx, __u32 idx)
 {
+    // rx->ring is saved in trusted memory during init
+    // it is a pointer to untrusted memory
 	const struct xdp_desc *descs = (const struct xdp_desc *)rx->ring;
 
+    // rx->mask is also in trusted memory,
+    // ensuring that descs[idx & rx->mask] is within ring mapped area
+    // however, we are consumers of this returned desc, so we should
+    // make sure it does not have invalid offest to umem; BUT verifying
+    // here is not the right way since that is an easy toctou: kernel could
+    // put valid address here but then change it before we use it; so the
+    // only way to do is in the xsk_umem__get_data function
 	return &descs[idx & rx->mask];
 }
 
 XDP_ALWAYS_INLINE int xsk_ring_prod__needs_wakeup(const struct xsk_ring_prod *r)
 {
+    // nothing to be done here .. the r->flags is pointer to untrusted memory
+    // (the ring's mapped area)
 	return *r->flags & XDP_RING_NEED_WAKEUP;
 }
 
@@ -97,10 +126,23 @@ XDP_ALWAYS_INLINE __u32 xsk_prod_nb_free(struct xsk_ring_prod *r, __u32 nb)
 	 * this function. Without this optimization it whould have been
 	 * free_entries = r->cached_prod - r->cached_cons + r->size.
 	 */
+    // We are producers in this ring. the only thing the kernel can manipulate
+    // is the r->consumer.. should we verify it? I dont think so, since the kernel
+    // can always advance/halt the consumer pointer and we cannot do anything about
+    // it. But we need to check that the value the kernel provides make sense
 	r->cached_cons = __atomic_load_n(r->consumer, __ATOMIC_ACQUIRE);
+
+    // The difference between a producer and a consumer should be
+    // at least 0, and at most r->size .. otherwise something is wrong
+    __u32 pending_slots = r->cached_prod - r->cached_cons;
+    if(r->cached_prod < r->cached_cons || // producer pointer always ahead
+            pending_slots > r->size){ // consumer cannot be more than r->size behind
+        err(EXIT_FAILURE, "Possbile manipulation by the kernel of the consumer pointer in xdp ring");
+    }
+
 	r->cached_cons += r->size;
 
-	return r->cached_cons - r->cached_prod;
+	return free_entries;
 }
 
 XDP_ALWAYS_INLINE __u32 xsk_cons_nb_avail(struct xsk_ring_cons *r, __u32 nb)
@@ -108,15 +150,25 @@ XDP_ALWAYS_INLINE __u32 xsk_cons_nb_avail(struct xsk_ring_cons *r, __u32 nb)
 	__u32 entries = r->cached_prod - r->cached_cons;
 
 	if (entries == 0) {
-		r->cached_prod = __atomic_load_n(r->producer, __ATOMIC_ACQUIRE);
-		entries = r->cached_prod - r->cached_cons;
-	}
+        // We are consumers in this ring. the only thing the kernel can manipulate
+        // is the r->producer.. should we verify it? I dont think so, since the kernel
+        // can always advance/halt the producer pointer and we cannot do anything about
+        // it.
+        r->cached_prod = __atomic_load_n(r->producer, __ATOMIC_ACQUIRE);
+
+        entries = r->cached_prod - r->cached_cons;
+        if(r->cached_prod < r->cached_cons || // producer pointer always ahead
+                entries > r->size){ // slots to consume cannot be more than r->size
+            err(EXIT_FAILURE, "Possbile manipulation by the kernel of the producer pointer in xdp ring");
+        }
+    }
 
 	return (entries > nb) ? nb : entries;
 }
 
 XDP_ALWAYS_INLINE __u32 xsk_ring_prod__reserve(struct xsk_ring_prod *prod, __u32 nb, __u32 *idx)
 {
+    // Nothing to verify here
 	if (xsk_prod_nb_free(prod, nb) < nb)
 		return 0;
 
@@ -131,11 +183,13 @@ XDP_ALWAYS_INLINE void xsk_ring_prod__submit(struct xsk_ring_prod *prod, __u32 n
 	/* Make sure everything has been written to the ring before indicating
 	 * this to the kernel by writing the producer pointer.
 	 */
+    // Nothing to verify here
 	__atomic_store_n(prod->producer, *prod->producer + nb, __ATOMIC_RELEASE);
 }
 
 XDP_ALWAYS_INLINE __u32 xsk_ring_cons__peek(struct xsk_ring_cons *cons, __u32 nb, __u32 *idx)
 {
+    // Nothing to verify here
 	__u32 entries = xsk_cons_nb_avail(cons, nb);
 
 	if (entries > 0) {
@@ -148,11 +202,13 @@ XDP_ALWAYS_INLINE __u32 xsk_ring_cons__peek(struct xsk_ring_cons *cons, __u32 nb
 
 XDP_ALWAYS_INLINE void xsk_ring_cons__cancel(struct xsk_ring_cons *cons, __u32 nb)
 {
+    // Nothing to verify here
 	cons->cached_cons -= nb;
 }
 
 XDP_ALWAYS_INLINE void xsk_ring_cons__release(struct xsk_ring_cons *cons, __u32 nb)
 {
+    // Nothing to verify here
 	/* Make sure data has been read before indicating we are done
 	 * with the entries by updating the consumer pointer.
 	 */
@@ -161,7 +217,31 @@ XDP_ALWAYS_INLINE void xsk_ring_cons__release(struct xsk_ring_cons *cons, __u32
 
 XDP_ALWAYS_INLINE void *xsk_umem__get_data(void *umem_area, __u64 addr)
 {
-	return &((char *)umem_area)[addr];
+    /*
+     * umem_area is the umem buffer, while the addr is the offset that we
+     * have read from the rings. so we need to make sure the resulting returned
+     * pointer is pointing to valid umem frame
+     * umem_area is pointer to untrusted memory, but the pointer
+     * itself is saved in trusted memory during init.
+     * addr is the offset into the umem, it is saved in trusted memory
+     *
+     * The question is, how should we verify? the size of the umem and the individual
+     * frame sizes are not passed here, nither are they global.
+     * FIXME: for now, we save them in global struct for validation here, this is bad; I know;
+     * but I think this is the only way without breaking the API
+     * also, I dont know what to do in case we found an error so for now I just err out
+     */
+
+    // umem_area should be the same as we have before
+    if((void*)umem_config_validation.addr != umem_area){
+        err(EXIT_FAILURE, "UMEM area address is invalid");
+    }
+    // addr should be within umem area with enough room for the frame
+    void* returned_frame = &((char *)umem_area)[addr];
+    if(returned_frame + umem_config_validation.chunk_size - XDP_PACKET_HEADROOM > umem_area + umem_config_validation.len){
+        err(EXIT_FAILURE, "UMEM offset is invalid: addr=%llu, cs=%u, len=%llu", addr, umem_config_validation.chunk_size, umem_config_validation.len);
+    }
+	return returned_frame;
 }
 
 XDP_ALWAYS_INLINE __u64 xsk_umem__extract_addr(__u64 addr)
diff --git a/lib/libxdp/libxdp.map b/lib/libxdp/libxdp.map
index 228307c..e73c4c9 100644
--- a/lib/libxdp/libxdp.map
+++ b/lib/libxdp/libxdp.map
@@ -66,4 +66,5 @@ LIBXDP_1.2.0 {
 		xsk_umem__extract_addr;
 		xsk_umem__extract_offset;
 		xsk_umem__get_data;
+        umem_config_validation;
 } LIBXDP_1.0.0;
diff --git a/lib/libxdp/xsk.c b/lib/libxdp/xsk.c
index d991a19..b12c98c 100644
--- a/lib/libxdp/xsk.c
+++ b/lib/libxdp/xsk.c
@@ -103,6 +103,8 @@ struct xdp_mmap_offsets_v1 {
 	struct xdp_ring_offset_v1 cr;
 };
 
+extern struct xdp_umem_reg umem_config_validation;
+
 /* Export all inline helpers as symbols for use by language bindings. */
 extern inline __u64 *xsk_ring_prod__fill_addr(struct xsk_ring_prod *fill,
 					      __u32 idx);
@@ -144,6 +146,25 @@ static bool xsk_page_aligned(void *buffer)
 	return !(addr & (getpagesize() - 1));
 }
 
+static bool is_running_in_gramine(){
+	return access("/dev/attestation", F_OK) == 0;
+}
+
+/**
+ * @brief makes sure that the offsets makes sense. We cannot really verify them because
+ * it can be different based on SMP cacheline alignment.. but at least we can verify
+ * the order and how they are mapped in the page
+ *
+ * @param off 
+ * @return true if valid
+ */
+static bool verify_xdp_mmap_offset(struct xdp_ring_offset* off){
+    return off->producer == 0 &&
+        off->consumer >= off->producer + sizeof(__u32) &&
+        off->flags >= off->consumer + sizeof(__u32) &&
+        off->desc >= off->flags + sizeof(__u32);
+}
+
 static void xsk_set_umem_config(struct xsk_umem_config *cfg,
 				const struct xsk_umem_config *usr_cfg)
 {
@@ -247,28 +268,42 @@ static int xsk_create_umem_rings(struct xsk_umem *umem, int fd,
 	void *map;
 	int err;
 
+    // tells the kernel to create the fill ring, but does not return it yet
 	err = setsockopt(fd, SOL_XDP, XDP_UMEM_FILL_RING,
 			 &umem->config.fill_size,
 			 sizeof(umem->config.fill_size));
 	if (err)
 		return -errno;
 
+    // tells the kernel to create the completion ring, but does not return it yet
 	err = setsockopt(fd, SOL_XDP, XDP_UMEM_COMPLETION_RING,
 			 &umem->config.comp_size,
 			 sizeof(umem->config.comp_size));
 	if (err)
 		return -errno;
 
+    // this gets the offsets of the rings within the fd-backed mmap page below
+    // this is copied in trusted memory by gramine
 	err = xsk_get_mmap_offsets(fd, &off);
 	if (err)
 		return -errno;
 
-	map = mmap(NULL, off.fr.desc + umem->config.fill_size * sizeof(__u64),
+    // verify provided offsets
+    if(!verify_xdp_mmap_offset(&off.fr) ||
+            !verify_xdp_mmap_offset(&off.cr))
+        return -EINVAL;
+
+	// make sure fill ring struct members offsets fit in map area
+    // gramine will make sure that mmaped area is in untrusted memory
+    size_t fr_size = umem->config.fill_size * sizeof(__u64);
+	size_t map_size = off.fr.desc + fr_size;
+	map = mmap(NULL, map_size,
 		   PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd,
 		   XDP_UMEM_PGOFF_FILL_RING);
 	if (map == MAP_FAILED)
 		return -errno;
 
+    // these will be verified before each use; no need to verify here
 	fill->mask = umem->config.fill_size - 1;
 	fill->size = umem->config.fill_size;
 	fill->producer = map + off.fr.producer;
@@ -285,6 +320,7 @@ static int xsk_create_umem_rings(struct xsk_umem *umem, int fd,
 		goto out_mmap;
 	}
 
+    // these will be verified before each use; no need to verify here
 	comp->mask = umem->config.comp_size - 1;
 	comp->size = umem->config.comp_size;
 	comp->producer = map + off.cr.producer;
@@ -299,12 +335,13 @@ out_mmap:
 	return err;
 }
 
+// first call into libxdp:
+// returned fill and comp rings will be in trusted memory
 int xsk_umem__create(struct xsk_umem **umem_ptr, void *umem_area,
 		     __u64 size, struct xsk_ring_prod *fill,
 		     struct xsk_ring_cons *comp,
 		     const struct xsk_umem_config *usr_config)
 {
-	struct xdp_umem_reg mr;
 	struct xsk_umem *umem;
 	int err;
 
@@ -313,10 +350,12 @@ int xsk_umem__create(struct xsk_umem **umem_ptr, void *umem_area,
 	if (!size && !xsk_page_aligned(umem_area))
 		return -EINVAL;
 
+    // in trusted memory:
 	umem = calloc(1, sizeof(*umem));
 	if (!umem)
 		return -ENOMEM;
 
+    // intercepted by gramine:
 	umem->fd = socket(AF_XDP, SOCK_RAW, 0);
 	if (umem->fd < 0) {
 		err = -errno;
@@ -327,19 +366,21 @@ int xsk_umem__create(struct xsk_umem **umem_ptr, void *umem_area,
 	INIT_LIST_HEAD(&umem->ctx_list);
 	xsk_set_umem_config(&umem->config, usr_config);
 
-	memset(&mr, 0, sizeof(mr));
-	mr.addr = (uintptr_t)umem_area;
-	mr.len = size;
-	mr.chunk_size = umem->config.frame_size;
-	mr.headroom = umem->config.frame_headroom;
-	mr.flags = umem->config.flags;
+	memset(&umem_config_validation, 0, sizeof(umem_config_validation));
+	umem_config_validation.addr = (uintptr_t)umem_area;
+	umem_config_validation.len = size;
+	umem_config_validation.chunk_size = umem->config.frame_size;
+	umem_config_validation.headroom = umem->config.frame_headroom;
+	umem_config_validation.flags = umem->config.flags;
 
-	err = setsockopt(umem->fd, SOL_XDP, XDP_UMEM_REG, &mr, sizeof(mr));
+    // intercepted by gramine, does not return data:
+	err = setsockopt(umem->fd, SOL_XDP, XDP_UMEM_REG, &umem_config_validation, sizeof(umem_config_validation));
 	if (err) {
 		err = -errno;
 		goto out_socket;
 	}
 
+    // inspected within xsk_create_umem_rings
 	err = xsk_create_umem_rings(umem, umem->fd, fill, comp);
 	if (err)
 		goto out_socket;
@@ -846,6 +887,7 @@ int xsk_setup_xdp_prog(int ifindex, int *xsks_map_fd)
 	return res;
 }
 
+// returned rx and tx rings will be in trusted memory
 int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 			      const char *ifname,
 			      __u32 queue_id, struct xsk_umem *umem,
@@ -867,15 +909,18 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 	if (!umem || !xsk_ptr || !(rx || tx))
 		return -EFAULT;
 
+    // allocated in trusted memory
 	xsk = calloc(1, sizeof(*xsk));
 	if (!xsk)
 		return -ENOMEM;
 
+    // nothing here
 	err = xsk_set_xdp_socket_config(&xsk->config, usr_config);
 	if (err)
 		goto out_xsk_alloc;
 
 	xsk->outstanding_tx = 0;
+    // this is trusted because it is emulated in gramine
 	ifindex = if_nametoindex(ifname);
 	if (!ifindex) {
 		err = -errno;
@@ -941,6 +986,11 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 	}
 
 	if (rx) {
+        if(!verify_xdp_mmap_offset(&off.rx)){
+            err = -EINVAL;
+            goto out_put_ctx;
+        }
+
 		rx_map = mmap(NULL, off.rx.desc +
 			      xsk->config.rx_size * sizeof(struct xdp_desc),
 			      PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE,
@@ -950,6 +1000,7 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 			goto out_put_ctx;
 		}
 
+        // will be verified before use
 		rx->mask = xsk->config.rx_size - 1;
 		rx->size = xsk->config.rx_size;
 		rx->producer = rx_map + off.rx.producer;
@@ -962,6 +1013,10 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 	xsk->rx = rx;
 
 	if (tx) {
+        if(!verify_xdp_mmap_offset(&off.rx)){
+            err = -EINVAL;
+            goto out_put_ctx;
+        }
 		tx_map = mmap(NULL, off.tx.desc +
 			      xsk->config.tx_size * sizeof(struct xdp_desc),
 			      PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE,
@@ -971,6 +1026,7 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 			goto out_mmap_rx;
 		}
 
+        // will be verified before use
 		tx->mask = xsk->config.tx_size - 1;
 		tx->size = xsk->config.tx_size;
 		tx->producer = tx_map + off.tx.producer;
@@ -995,6 +1051,7 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 		sxdp.sxdp_flags = xsk->config.bind_flags;
 	}
 
+    // really nothing to do here
 	err = bind(xsk->fd, (struct sockaddr *)&sxdp, sizeof(sxdp));
 	if (err) {
 		err = -errno;
@@ -1002,9 +1059,15 @@ int xsk_socket__create_shared(struct xsk_socket **xsk_ptr,
 	}
 
 	if (!(xsk->config.libbpf_flags & XSK_LIBBPF_FLAGS__INHIBIT_PROG_LOAD)) {
-		err = __xsk_setup_xdp_prog(xsk, NULL);
-		if (err)
-			goto out_mmap_tx;
+		if (is_running_in_gramine()) {
+			pr_info("Skipping XDP program setup: XDP program setup will be taken care of from within Gramine.\n"
+					"\tJust make sure you have correctly configured Gramine to communicate to a control socket.\n"
+					"\tSee CI-Examples/socket-types-profiler/src/perf.manifest.template\n");
+		}else{
+			err = __xsk_setup_xdp_prog(xsk, NULL);
+			if (err)
+				goto out_mmap_tx;
+		}
 	}
 
 	*xsk_ptr = xsk;
